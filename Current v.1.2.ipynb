{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c0acfe-696a-49ed-a125-4f5d78a7881a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50000/50000 [1:24:49<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median values and errors:\n",
      "t0: 2430.15372 (+0.00007, -0.00007)\n",
      "rp: 0.13672 (+0.00018, -0.00018)\n",
      "per: 2.77094 (+0.00002, -0.00002)\n",
      "a: 9.69858 (+0.01338, -0.01322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n",
      "WARNING:root:Too few points to create valid contours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance fraction: 0.5918806249999999\n",
      "Median values and errors:\n",
      "t0: 2430.15372 (+0.00007, -0.00007)\n",
      "rp: 0.13672 (+0.00018, -0.00018)\n",
      "per: 2.77094 (+0.00002, -0.00002)\n",
      "a: 9.69858 (+0.01338, -0.01322)\n",
      "Chi-squared value: nan\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import batman\n",
    "from scipy.optimize import minimize\n",
    "from scipy.signal import find_peaks\n",
    "import emcee\n",
    "import corner\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load data\n",
    "data_file = \"tess2021.csv\"\n",
    "if not os.path.exists(data_file):\n",
    "    raise FileNotFoundError(f\"The file {data_file} does not exist. Please provide the correct path.\")\n",
    "\n",
    "data_planet = pd.read_csv(data_file)\n",
    "time_data = np.array(data_planet['time'])\n",
    "flux_data = np.array(data_planet['flux'])\n",
    "flux_err = np.ones_like(flux_data) * 0.001  # Assuming a constant error for simplicity\n",
    "\n",
    "# Defines initial parameters\n",
    "initial_params = batman.TransitParams()\n",
    "initial_params.t0 = 2430.15  # time of inferior conjunction; mid-transit time in days\n",
    "initial_params.per = 2.770860  # orbital period in days (estimated)\n",
    "initial_params.rp = 0.2  # planet radius (in units of stellar radii)\n",
    "initial_params.a = 15  # semi-major axis (in units of stellar radii)\n",
    "initial_params.inc = 87.47  # orbital inclination (in degrees)\n",
    "initial_params.ecc = 0  # eccentricity\n",
    "initial_params.w = 90  # longitude of periastron (in degrees)\n",
    "initial_params.limb_dark = \"quadratic\"  # limb darkening model\n",
    "initial_params.u = [0.1, 0.3]  # limb darkening coefficients\n",
    "\n",
    "# Function to detect the first dip in the data\n",
    "def find_first_dip(flux, prominence=0.01):\n",
    "    peaks, _ = find_peaks(-flux, prominence=prominence)\n",
    "    if peaks.any():\n",
    "        return peaks[0]\n",
    "    return None\n",
    "\n",
    "# Define a function to generate the model light curve\n",
    "def generate_model(params, time):\n",
    "    m = batman.TransitModel(params, time)\n",
    "    return m.light_curve(params)\n",
    "\n",
    "# Define a function for a preliminary fit to estimate rp\n",
    "def preliminary_fit(params, time, flux):\n",
    "    model_flux = generate_model(params, time)\n",
    "    return np.sum((flux - model_flux) ** 2)\n",
    "\n",
    "# Use scipy.optimize.minimize to estimate rp\n",
    "def estimate_initial_rp(time, flux, initial_params):\n",
    "    def objective(rp):\n",
    "        params = initial_params\n",
    "        params.rp = rp\n",
    "        return preliminary_fit(params, time, flux)\n",
    "    \n",
    "    result = minimize(objective, x0=[initial_params.rp], bounds=[(0.01, 1.0)])\n",
    "    return result.x[0]\n",
    "\n",
    "# Estimate rp\n",
    "initial_params.rp = estimate_initial_rp(time_data, flux_data, initial_params)\n",
    "\n",
    "# Define a log-likelihood function for MCMC\n",
    "def log_likelihood(theta, time, flux, flux_err):\n",
    "    t0, rp, per, a = theta\n",
    "    params = batman.TransitParams()\n",
    "    params.t0 = t0\n",
    "    params.rp = rp\n",
    "    params.per = per\n",
    "    params.a = a\n",
    "    params.inc = initial_params.inc\n",
    "    params.ecc = initial_params.ecc\n",
    "    params.w = initial_params.w\n",
    "    params.limb_dark = initial_params.limb_dark\n",
    "    params.u = initial_params.u\n",
    "\n",
    "    model = generate_model(params, time)\n",
    "    sigma2 = flux_err**2\n",
    "\n",
    "    if np.any(np.isnan(model)):\n",
    "        return -np.inf\n",
    "\n",
    "    return -0.5 * np.sum((flux - model)**2 / sigma2 + np.log(sigma2))\n",
    "\n",
    "# Define a log-prior function for MCMC\n",
    "def log_prior(theta):\n",
    "    t0, rp, per, a = theta\n",
    "    if (initial_params.t0 - 5 < t0 < initial_params.t0 + 5 and \n",
    "        0.1 < rp < 1.0 and \n",
    "        initial_params.per * 0.8 < per < initial_params.per * 1.2 and \n",
    "        initial_params.a * 0.1 < a < initial_params.a * 10):\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "# Define a log-probability function for MCMC\n",
    "def log_probability(theta, time, flux, flux_err):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    ll = log_likelihood(theta, time, flux, flux_err)\n",
    "    if not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    return lp + ll\n",
    "\n",
    "# Enhanced flux data filtering to remove NaN values\n",
    "filtered_idx = pd.notnull(flux_data) & pd.notnull(time_data) & pd.notnull(flux_err)\n",
    "filtered_flux = flux_data[filtered_idx]\n",
    "filtered_time = time_data[filtered_idx]\n",
    "filtered_err = flux_err[filtered_idx]\n",
    "# Set up the MCMC sampler\n",
    "nwalkers = 32\n",
    "ndim = 4\n",
    "initial_guess = [initial_params.t0, initial_params.rp, initial_params.per, initial_params.a]\n",
    "pos = initial_guess + 1e-4 * np.random.randn(nwalkers, ndim)\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, args=(filtered_time, filtered_flux, filtered_err))\n",
    "\n",
    "# File to save the MCMC chain\n",
    "chain_file = \"mcmc_chain.npy\"\n",
    "\n",
    "if os.path.exists(chain_file):\n",
    "    # Load the chain if it exists\n",
    "    sampler.run_mcmc(pos, 0, progress=False)  # Initialize the sampler\n",
    "    sampler.chain = np.load(chain_file)\n",
    "else:\n",
    "    # Run MCMC and save the chain to a file\n",
    "    sampler.run_mcmc(pos, 50000, progress=True)\n",
    "    np.save(chain_file, sampler.get_chain())\n",
    "\n",
    "# Get the MCMC results\n",
    "samples = sampler.get_chain(discard=200, thin=1, flat=True)\n",
    "t0_mcmc, rp_mcmc, per_mcmc, a_mcmc = np.percentile(samples, 50, axis=0)\n",
    "\n",
    "# Calculate median and 16th, 84th percentiles for each parameter\n",
    "medians = np.percentile(samples, 50, axis=0)\n",
    "errors_lower = np.percentile(samples, 16, axis=0)\n",
    "errors_upper = np.percentile(samples, 84, axis=0)\n",
    "\n",
    "parameters = [\"t0\", \"rp\", \"per\", \"a\"]\n",
    "\n",
    "print(\"Median values and errors:\")\n",
    "for i, param in enumerate(parameters):\n",
    "    print(f\"{param}: {medians[i]:.5f} (+{errors_upper[i] - medians[i]:.5f}, -{medians[i] - errors_lower[i]:.5f})\")\n",
    "\n",
    "\n",
    "# Trace plots\n",
    "fig, axes = plt.subplots(4, figsize=(10, 7), sharex=True)\n",
    "labels = [\"t0\", \"rp\", \"per\", \"a\"]\n",
    "all_samples = sampler.get_chain()\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(all_samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_ylabel(labels[i])\n",
    "axes[-1].set_xlabel(\"Step number\")\n",
    "plt.savefig(\"trace_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Corner plot\n",
    "fig = corner.corner(samples, labels=[\"t0\", \"rp\", \"per\", \"a\"], show_titles=True, title_fmt=\".2e\", quantiles=[0.16, 0.5, 0.84])\n",
    "plt.savefig(\"corner_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Print acceptance fraction\n",
    "print(\"Acceptance fraction:\", np.mean(sampler.acceptance_fraction))\n",
    "\n",
    "# Define a function to fit transit parameters and generate the model light curve\n",
    "def fit_transit_parameters(time, flux, initial_params):\n",
    "    # Detect the first dip\n",
    "    first_dip_index = find_first_dip(flux)\n",
    "\n",
    "    if first_dip_index is not None:\n",
    "        # Use the first dip as the initial transit center time\n",
    "        initial_params.t0 = time[first_dip_index]\n",
    "\n",
    "    # Define the transit model parameters\n",
    "    params = batman.TransitParams()\n",
    "    params.t0 = t0_mcmc\n",
    "    params.per = per_mcmc\n",
    "    params.rp = rp_mcmc\n",
    "    params.a = a_mcmc\n",
    "    params.inc = initial_params.inc\n",
    "    params.ecc = initial_params.ecc\n",
    "    params.w = initial_params.w\n",
    "    params.limb_dark = initial_params.limb_dark\n",
    "    params.u = initial_params.u\n",
    "\n",
    "    # Generate a finer time grid during transit for a smoother model\n",
    "    time_fine = np.linspace(time[0], time[-1], len(time) * 10)\n",
    "    m = batman.TransitModel(params, time_fine)\n",
    "\n",
    "    # Calculate the model light curve\n",
    "    flux_model = m.light_curve(params)\n",
    "\n",
    "    return time_fine, flux_model, [params.t0, params.rp, params.per, params.a]\n",
    "\n",
    "# Generate the model light curve with best-fit parameters\n",
    "time_fine, flux_model, temp_best_fit_params = fit_transit_parameters(time_data, flux_data, initial_params)\n",
    "\n",
    "# Phase-fold the model\n",
    "model_phase = ((time_fine - temp_best_fit_params[0] + 0.5 * temp_best_fit_params[2]) % temp_best_fit_params[2]) / temp_best_fit_params[2] - 0.5\n",
    "\n",
    "# Phase-fold the data\n",
    "phase_folded_time = ((time_data - temp_best_fit_params[0] + 0.5 * temp_best_fit_params[2]) % temp_best_fit_params[2]) / temp_best_fit_params[2] - 0.5\n",
    "\n",
    "# Sorting the phase and corresponding flux data for plotting\n",
    "sort_order_data = np.argsort(phase_folded_time)\n",
    "sorted_flux = flux_data[sort_order_data]\n",
    "sorted_phase = phase_folded_time[sort_order_data]\n",
    "\n",
    "sort_order_model = np.argsort(model_phase)\n",
    "sorted_model_flux = flux_model[sort_order_model]\n",
    "sorted_model_phase = model_phase[sort_order_model]\n",
    "\n",
    "# Plot the observed data without connecting the blue points\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sorted_phase, sorted_flux, 'bo', label='Observed Data', markersize=2)\n",
    "plt.plot(sorted_model_phase, sorted_model_flux, 'r-', label='Model Light Curve')\n",
    "plt.xlabel('Phase')\n",
    "plt.ylabel('Flux')\n",
    "plt.legend()\n",
    "plt.savefig(\"transit_fit.png\")\n",
    "plt.close()\n",
    "\n",
    "# Print the median values and errors\n",
    "print(\"Median values and errors:\")\n",
    "for i, param in enumerate([\"t0\", \"rp\", \"per\", \"a\"]):\n",
    "    print(f\"{param}: {medians[i]:.5f} (+{errors_upper[i] - medians[i]:.5f}, -{medians[i] - errors_lower[i]:.5f})\")\n",
    "\n",
    "# Calculate and print chi-squared value\n",
    "chi_squared = np.sum(((sorted_flux - np.interp(sorted_phase, sorted_model_phase, sorted_model_flux)) / flux_err[:len(sorted_flux)]) ** 2)\n",
    "print(\"Chi-squared value:\", chi_squared)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
